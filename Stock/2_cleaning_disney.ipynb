{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
      "       'Stock Splits'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('datasets/training_disney.csv', 'datasets/testing_disney.csv')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#loading dataset \n",
    "file_path = 'datasets/disney_daily.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# checking for column names, since I want to remove everything except Date and Close\n",
    "print(\"Columns in the dataset:\", data.columns)\n",
    "\n",
    "#converting to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce', utc=True).dt.tz_localize(None)\n",
    "\n",
    "# dropping any rows with invalid date format if there are any\n",
    "data.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "# keeping only Date and Close columns\n",
    "data = data[['Date', 'Close']]\n",
    "\n",
    "# splitting the dataset into training and testing based on the dates\n",
    "training_data = data[data['Date'] <= pd.to_datetime('2019-12-31')]\n",
    "testing_data = data[data['Date'] >= pd.to_datetime('2020-01-01')]\n",
    "\n",
    "# saving the files\n",
    "training_file_path = 'datasets/training_disney.csv'\n",
    "testing_file_path = 'datasets/testing_disney.csv'\n",
    "\n",
    "training_data.to_csv(training_file_path, index=False)\n",
    "testing_data.to_csv(testing_file_path, index=False)\n",
    "\n",
    "training_file_path, testing_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cleaned both of the datasets (Disney and Warner Bros) the same way to keep consistency. Which is keeping only Date and Close columns, removing invalid or missing dates and converting Date column to datetime format. Then I splitted the dataset into two diles: training and testing like in Warner Bros. The dataset thanks to that is well structured and clear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
